# app.py
# =============================================================================
# Application Streamlit : √âvaluation du risque cr√©dit (PD)
# - Scoring unitaire (formulaire)
# - Scoring par lot (CSV)
# - Chargement auto du meilleur mod√®le dans artifacts/
# =============================================================================

import json
from datetime import datetime
from pathlib import Path
from typing import Optional, Tuple

import joblib
import pandas as pd
import sklearn
import streamlit as st

# -----------------------------------------------------------------------------#
# Config de page
# -----------------------------------------------------------------------------#
st.set_page_config(page_title="Risque cr√©dit - PD", page_icon="üìä", layout="centered")

# -----------------------------------------------------------------------------#
# En-t√™te
# -----------------------------------------------------------------------------#
st.title("√âvaluation du risque cr√©dit : probabilit√© de d√©faut de paiement par client")
st.caption(
    "Application acad√©mique : estimation de la probabilit√© de d√©faut √† partir des caract√©ristiques du client."
)
st.divider()

# -----------------------------------------------------------------------------#
# 1) Artefacts (mod√®le + m√©triques) ‚Äì d√©couverte automatique
# -----------------------------------------------------------------------------#
ART = Path("artifacts")
ART.mkdir(exist_ok=True)

# Ordre des features attendu par le pipeline (doit matcher l'entra√Ænement)
REQUIRED = [
    "credit_lines_outstanding",
    "loan_amt_outstanding",
    "total_debt_outstanding",
    "income",
    "years_employed",
    "fico_score",
]

# Strat√©gie de d√©couverte : MLflow > *_final.joblib > n'importe quel .joblib
candidates = []
candidates += sorted(ART.glob("best_model_from_mlflow_*.joblib"))
candidates += sorted(ART.glob("*_final.joblib"))
candidates += sorted(ART.glob("*.joblib"))

MODEL_PATH: Optional[Path] = candidates[0] if candidates else None
METRICS_PATH = ART / "best_model_metrics.json"

# Charger m√©triques (si pr√©sentes)
metrics = {}
if METRICS_PATH.exists():
    try:
        metrics = json.loads(METRICS_PATH.read_text())
    except Exception as e:
        st.warning(f"Impossible de lire les m√©triques ('{METRICS_PATH.name}') : {e}")


@st.cache_resource
def load_model(path: Path):
    """Charge le mod√®le depuis un fichier .joblib (mis en cache)."""
    return joblib.load(path)


model = None
if MODEL_PATH and MODEL_PATH.exists():
    try:
        model = load_model(MODEL_PATH)
    except Exception as e:
        st.error(f"Erreur au chargement du mod√®le ({MODEL_PATH.name}) : {e}")
else:
    st.error(
        "Aucun mod√®le trouv√© dans 'artifacts/'. "
        "Ex√©cute l'entra√Ænement/MLflow pour sauvegarder un mod√®le (.joblib)."
    )

# Panneau d‚Äôinfos techniques
with st.expander("‚ÑπÔ∏è Informations mod√®le (cliquer pour afficher)"):
    st.markdown(
        f"**Fichier mod√®le charg√© :** `{MODEL_PATH.name if MODEL_PATH else '‚Äî'}`"
    )
    if metrics:
        st.markdown(
            f"- **ROC-AUC (test)** : {metrics.get('roc_auc', 0):.3f}  \n"
            f"- **PR-AUC (test)**  : {metrics.get('pr_auc', 0):.3f}  \n"
            f"- **Brier score**    : {metrics.get('brier', 0):.3f}  \n"
            f"- **Accuracy**       : {metrics.get('accuracy', 0):.3%}"
        )
    st.markdown(f"- **scikit-learn (inference)** : `{sklearn.__version__}`")
    st.markdown(f"- **Date d‚Äôex√©cution** : {datetime.now().strftime('%Y-%m-%d %H:%M')}")
st.divider()

# -----------------------------------------------------------------------------#
# 2) Aides / d√©finitions
# -----------------------------------------------------------------------------#
st.markdown(
    "Analysez le profil de chaque client pour **anticiper le risque de d√©faut** et "
    "prendre des **d√©cisions de cr√©dit √©clair√©es**."
)
st.divider()


# -----------------------------------------------------------------------------#
# 3) Utilitaires (formatage + logique m√©tier)
# -----------------------------------------------------------------------------#
def fmt_eur(x: float) -> str:
    """Format mon√©taire simple (fr)."""
    try:
        return f"{x:,.0f} ‚Ç¨".replace(",", " ").replace(".", ",")
    except Exception:
        return str(x)


def verdict_message(pd_value: float, threshold: float) -> Tuple[str, str]:
    """Retourne un niveau de risque lisible + une recommandation m√©tier."""
    if pd_value < 0.10:
        level = "Faible"
        advice = "Accepter le cr√©dit (conditions standard)."
    elif pd_value < 0.30:
        level = "Mod√©r√©"
        advice = (
            "Accepter sous conditions (limite d‚Äôendettement / stabilit√© des revenus)."
        )
    elif pd_value < threshold:
        level = "√âlev√© (mais < seuil)"
        advice = "√âtudier des garanties ou r√©duire le montant."
    else:
        level = "Tr√®s √©lev√© (‚â• seuil)"
        advice = "Demander des garanties fortes ou refuser."
    return level, advice


def ensure_frame_order_and_type(df: pd.DataFrame) -> pd.DataFrame:
    """
    S√©lectionne et ordonne les colonnes requises + cast types.
    - Entiers pour certaines colonnes
    - Float pour les autres
    """
    X = df[REQUIRED].copy()
    int_cols = ["credit_lines_outstanding", "years_employed", "fico_score"]
    float_cols = [c for c in REQUIRED if c not in int_cols]

    for c in int_cols:
        X[c] = pd.to_numeric(X[c], errors="coerce").fillna(0).astype("int64")
    for c in float_cols:
        X[c] = pd.to_numeric(X[c], errors="coerce").fillna(0.0).astype("float64")
    return X


# -----------------------------------------------------------------------------#
# 4) Score unitaire (formulaire)
# -----------------------------------------------------------------------------#
st.subheader("Score unitaire")

col1, col2 = st.columns(2)
with col1:
    credit_lines_outstanding = st.number_input(
        "Lignes de cr√©dit actives",
        min_value=0,
        step=1,
        value=1,
        help="Nombre de lignes de cr√©dit actuellement ouvertes pour le client.",
    )
    loan_amt_outstanding = st.number_input(
        "Montant du pr√™t en cours (‚Ç¨)",
        min_value=0.0,
        step=100.0,
        value=3000.0,
        help="Montant du pr√™t cibl√© encore √† rembourser.",
    )
    total_debt_outstanding = st.number_input(
        "Dette totale (‚Ç¨)",
        min_value=0.0,
        step=100.0,
        value=8000.0,
        help="Somme de toutes les dettes du client (tous cr√©dits confondus).",
    )
with col2:
    income = st.number_input(
        "Revenu annuel (‚Ç¨)",
        min_value=0.0,
        step=100.0,
        value=60000.0,
        help="Revenu brut annuel estim√© du client.",
    )
    years_employed = st.number_input(
        "Anciennet√© (ann√©es)",
        min_value=0,
        step=1,
        value=5,
        help="Nombre d'ann√©es d'emploi du client.",
    )
    fico_score = st.number_input(
        "Score FICO (300‚Äì850)",
        min_value=300,
        max_value=850,
        step=1,
        value=640,
        help="Indicateur de solvabilit√© (plus √©lev√© = plus fiable).",
    )

theta = st.slider(
    "Seuil d√©cisionnel (Œ∏)",
    0.05,
    0.95,
    0.50,
    0.01,
    help="Au-dessus du seuil ‚Üí Risque √©lev√©. En dessous ‚Üí Fiable. Ajuster selon le co√ªt FP/FN.",
)

if st.button("‚öôÔ∏è Pr√©dire la probabilit√© de d√©faut (PD)"):
    if model is None:
        st.error(
            "Mod√®le non charg√©. V√©rifie les artefacts ou les versions de librairies."
        )
    elif not hasattr(model, "predict_proba"):
        st.error(
            "Le mod√®le charg√© ne poss√®de pas 'predict_proba'. V√©rifie le pipeline sauvegard√©."
        )
    else:
        # Construire un DataFrame une-ligne et assurer ordre + types
        df_one = pd.DataFrame(
            [
                {
                    "credit_lines_outstanding": credit_lines_outstanding,
                    "loan_amt_outstanding": loan_amt_outstanding,
                    "total_debt_outstanding": total_debt_outstanding,
                    "income": income,
                    "years_employed": years_employed,
                    "fico_score": fico_score,
                }
            ]
        )
        X = ensure_frame_order_and_type(df_one)

        # ---> FIX du warning NumPy : on extrait un scalaire [0, 1] puis .item()
        pd_hat: float = model.predict_proba(X)[0, 1].item()
        verdict_is_risk = pd_hat >= theta

        st.metric("Probabilit√© de d√©faut (PD)", f"{pd_hat:.2%}")
        niveau, reco = verdict_message(pd_hat, theta)

        if verdict_is_risk:
            st.markdown(
                "<div style='padding:10px;border-radius:8px;background:#ffe6e6;color:#a80000;font-weight:600;'>"
                f"‚ùå Verdict : Risque √©lev√© ‚Äî PD = {pd_hat:.2%} (niveau : {niveau}). "
                f"**D√©cision sugg√©r√©e : {reco}**</div>",
                unsafe_allow_html=True,
            )
        else:
            st.markdown(
                "<div style='padding:10px;border-radius:8px;background:#e9f7ef;color:#1e7e34;font-weight:600;'>"
                f"‚úÖ Verdict : Fiable ‚Äî PD = {pd_hat:.2%} (niveau : {niveau}). "
                f"**D√©cision sugg√©r√©e : {reco}**</div>",
                unsafe_allow_html=True,
            )

        with st.expander("D√©tails de la saisie"):
            st.write(
                {
                    "Lignes de cr√©dit actives": credit_lines_outstanding,
                    "Montant du pr√™t en cours": fmt_eur(loan_amt_outstanding),
                    "Dette totale": fmt_eur(total_debt_outstanding),
                    "Revenu annuel": fmt_eur(income),
                    "Anciennet√© (ann√©es)": years_employed,
                    "Score FICO": fico_score,
                    "Seuil (Œ∏)": round(theta, 2),
                }
            )

st.divider()

# -----------------------------------------------------------------------------#
# 5) Scoring par lot (CSV)
# -----------------------------------------------------------------------------#
st.subheader("Scoring par lot (CSV)")

st.markdown(
    "#### Comment √ßa marche ?\n"
    "1. **T√©l√©chargez le mod√®le de CSV** ci-dessous et remplissez-le avec vos clients.\n"
    "2. **Importez** le fichier via le bouton.\n"
    "3. L‚Äôapp calcule **PD** + **verdict** pour chaque ligne.\n"
    "4. **T√©l√©chargez** le fichier enrichi pour vos d√©cisions."
)

show_explanatory = st.checkbox(
    "Ajouter des colonnes explicatives (niveau de risque, recommandation)", value=False
)

# Mini-exemple pour CSV mod√®le
sample = pd.DataFrame(
    [
        {
            "credit_lines_outstanding": 1,
            "loan_amt_outstanding": 3500,
            "total_debt_outstanding": 9000,
            "income": 65000,
            "years_employed": 4,
            "fico_score": 630,
        }
    ]
)
st.download_button(
    "‚¨áÔ∏è T√©l√©charger un CSV mod√®le",
    sample.to_csv(index=False).encode("utf-8"),
    "modele_clients.csv",
    "text/csv",
)

file = st.file_uploader("Importer un CSV", type=["csv"])

if file:
    if model is None:
        st.error("Mod√®le non charg√©. Impossible de scorer le CSV.")
    elif not hasattr(model, "predict_proba"):
        st.error(
            "Le mod√®le charg√© ne poss√®de pas 'predict_proba'. V√©rifie le pipeline sauvegard√©."
        )
    else:
        try:
            df = pd.read_csv(file)
        except Exception as e:
            st.error(f"Erreur de lecture du CSV : {e}")
            df = None

        if df is not None:
            missing = [c for c in REQUIRED if c not in df.columns]
            if missing:
                st.error(f"Colonnes manquantes : {missing}")
            else:
                Xb = ensure_frame_order_and_type(df)
                out = df.copy()
                # Pour un batch, on garde un vecteur de probabilit√©s (pas de cast float seule)
                out["pd"] = model.predict_proba(Xb)[:, 1]
                out["verdict"] = (out["pd"] >= theta).map(
                    {True: "Risque √©lev√©", False: "Fiable"}
                )

                if show_explanatory:
                    niveaux, recos = [], []
                    for p in out["pd"].tolist():
                        lvl, rc = verdict_message(float(p), theta)
                        niveaux.append(lvl)
                        recos.append(rc)
                    out["niveau_risque"] = niveaux
                    out["recommandation"] = recos

                st.dataframe(out.head(20), use_container_width=True)
                st.download_button(
                    "üíæ T√©l√©charger les r√©sultats (CSV)",
                    out.to_csv(index=False).encode("utf-8"),
                    "predictions.csv",
                    "text/csv",
                )

# -----------------------------------------------------------------------------#
# 6) Pied de page
# -----------------------------------------------------------------------------#
st.divider()
st.markdown("üë§ **Auteur :** Colins DONGMO ‚Äî Master Data Science")
